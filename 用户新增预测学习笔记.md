# 用户新增预测baseline模型测试
    通过推荐进入讯飞官网，选择了机器学习赛道中的用户新增预测挑战赛，由于之前是做机器学习相关科研， 
    所以对机器学习工作有一定的基础，这次参赛的目的是希望和大家一起多多交流，共同进步；也希望自己
    能够学到一些新技术和不错的想法。
## baseline模型代码和自己的一些理解
    import pandas as pd
    import numpy as np
    
    train_data = pd.read_csv('用户新增预测挑战赛公开数据/train.csv')
    test_data = pd.read_csv('用户新增预测挑战赛公开数据/test.csv')
    
    train_data['common_ts'] = pd.to_datetime(train_data['common_ts'], unit='ms')
    test_data['common_ts'] = pd.to_datetime(test_data['common_ts'], unit='ms')

    这段代码是通过pandas库的read_csv方法来读取数据表格，将数据表格转化为DataFrame对象，方便后续操作；
    使用to_datetime方法对数据集中的“common_ts”列中的日期进行转换，将数据进行处理。

    def udmap_onethot(d):
    v = np.zeros(9)
    if d == 'unknown':
        return v
    
    d = eval(d)
    for i in range(1, 10):
        if 'key' + str(i) in d:
            v[i-1] = d['key' + str(i)]
            
    return v

    train_udmap_df = pd.DataFrame(np.vstack(train_data['udmap'].apply(udmap_onethot)))
    test_udmap_df = pd.DataFrame(np.vstack(test_data['udmap'].apply(udmap_onethot)))
    
    train_udmap_df.columns = ['key' + str(i) for i in range(1, 10)]
    test_udmap_df.columns = ['key' + str(i) for i in range(1, 10)]

    这段代码是对udmap列的一个数据处理，其中该列包含两种类型，第一种是unknown，另一种是含有采集到的信息。
    构造了一个函数，其功能是对该列进行数据处理，其中对于unknown字段处理，直接返回一个含有9个0元素的一维数组；
    其它字段，返回一个对应长度的构造数组，最后将其应用在udmap列上。

    train_data = pd.concat([train_data, train_udmap_df], axis=1)
    test_data = pd.concat([test_data, test_udmap_df], axis=1)

    train_data['eid_freq'] = train_data['eid'].map(train_data['eid'].value_counts())
    test_data['eid_freq'] = test_data['eid'].map(train_data['eid'].value_counts())
    
    train_data['eid_mean'] = train_data['eid'].map(train_data.groupby('eid')['target'].mean())
    test_data['eid_mean'] = test_data['eid'].map(train_data.groupby('eid')['target'].mean())

    train_data['udmap_isunknown'] = (train_data['udmap'] == 'unknown').astype(int)
    test_data['udmap_isunknown'] = (test_data['udmap'] == 'unknown').astype(int)

    train_data['common_ts_hour'] = train_data['common_ts'].dt.hour
    test_data['common_ts_hour'] = test_data['common_ts'].dt.hour

    以上这段代码均是对数据集的字段进行数据处理，第一部分是将数据集和构造好新的udmap字段以列的方式将其连接起来；
    第二部分是为每个eid元素计算频率（即出现次数），并将这些频率值映射到新的eid_freq列中，以便后续分析或处理；
    第三部分是在train_data中，为每个唯一的eid元素计算其对应的目标值平均值，并将这些平均值映射到新的eid_mean列中;
    第四部分代码是构建一个新的列，该列是判断对应的udmap列是否为“unknown”,并将判断的结果转换为int类型，然后将其赋值给
    新的列；第五部分是对时间戳列进行操作，从时间戳中提取小时信息，并将小时信息映射到新的列中。

    import lightgbm as lgb
    from sklearn.linear_model import LogisticRegression
    from sklearn.tree import DecisionTreeClassifier
    
    clf = DecisionTreeClassifier()
    clf.fit(
        train_data.drop(['udmap', 'common_ts', 'uuid', 'target'], axis=1),
        train_data['target']
    )


    这一部分是将构造一个决策树分类器，并用处理后的训练集和目标值进行训练
    
    pd.DataFrame({
        'uuid': test_data['uuid'],
        'target': clf.predict(test_data.drop(['udmap', 'common_ts', 'uuid'], axis=1))
    }).to_csv('submit.csv', index=None)

    这一部分是将训练好的模型，用于预测测试集，得出预测结果，并将预测结果转化为csv格式，存储在submit.csv表中。

    将baseline模型进行一遍测试后，得到一些思路，比如对udmap字段如何处理，该方法是将其构造为一个数组；我因此联想到
    可以用sklearn方法，将字典中的值提取出来然后构造一个新的列；和群里小伙伴的交流，也得到了一个思路，对于如何提升
    f1_score分数，可以在构造新特征方面下手，另外应该多尝试一些模型，得出最佳模型，然后对最佳模型进行一个超参数优化，
    这也是一个很不错的思路。总之，接下来可以试试相关方法，是否对提升分数有所帮助。
